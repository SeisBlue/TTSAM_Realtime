#!/usr/bin/env python3
"""
TTSAM Mock Server
ç”¨æ–¼å‰ç«¯é–‹ç™¼æ¸¬è©¦ï¼Œä¸ä¾è³´ Earthworm å’Œ PyEarthworm
"""

import json
import os
import random
import threading
import time

import numpy as np
import pandas as pd
from flask import Flask, render_template, request
from flask_socketio import SocketIO
from flask_cors import CORS
from loguru import logger

# ========== Flask App Setup ==========
app = Flask(__name__)
CORS(app, resources={r"/api/*": {"origins": "*"}})
socketio = SocketIO(app, cors_allowed_origins="*")

# ========== Load Target Stations ==========
target_file = "data/eew_target.csv"
try:
    logger.info(f"Loading {target_file}...")
    target_df = pd.read_csv(target_file)
    target_dict = target_df.to_dict(orient="records")
    logger.success(f"âœ… Loaded {len(target_dict)} target stations")
except FileNotFoundError:
    logger.warning(f"âŒ {target_file} not found, using dummy data")
    target_dict = [
        {"station": "MOCK1", "station_zh": "æ¨¡æ“¬ç«™1", "county": "å°åŒ—å¸‚", "lat": 25.0, "lon": 121.5},
        {"station": "MOCK2", "station_zh": "æ¨¡æ“¬ç«™2", "county": "æ–°åŒ—å¸‚", "lat": 25.1, "lon": 121.6},
        {"station": "MOCK3", "station_zh": "æ¨¡æ“¬ç«™3", "county": "æ¡ƒåœ’å¸‚", "lat": 24.9, "lon": 121.3},
    ]

# ========== Web Routes ==========
@app.route("/", methods=["GET"])
def index():
    """é¦–é  - é¡¯ç¤ºå ±å‘Šæ¸…å–®"""
    report_log_dir = "logs/report"
    try:
        files = []
        for f in os.listdir(report_log_dir):
            file_path = os.path.join(report_log_dir, f)
            if (
                f.startswith("report")
                and f.endswith(".log")
                and os.path.isfile(file_path)
            ):
                files.append(f)
        files.sort(
            key=lambda x: os.path.getmtime(os.path.join(report_log_dir, x)),
            reverse=True,
        )
    except FileNotFoundError:
        files = []
        logger.warning(f"âŒ {report_log_dir} not found")

    return render_template("index.html", files=files, target=target_dict)


@app.route("/get_file_content")
def get_file_content():
    """å–å¾—å ±å‘Šæª”æ¡ˆå…§å®¹"""
    report_log_dir = "logs/report"
    file_name = request.args.get("file")

    # å®‰å…¨æ€§æª¢æŸ¥
    if not file_name.startswith("report"):
        return "Invalid file type", 400
    if not file_name.endswith(".log"):
        return "Invalid file type", 400
    if ".." in file_name or "/" in file_name or "\\" in file_name:
        return "Invalid file name", 400

    try:
        file_path = os.path.join(report_log_dir, file_name)
        with open(file_path, "r", encoding="utf-8") as file:
            content = file.read()
        return content
    except Exception as e:
        logger.error(f"âŒ Error reading file: {e}")
        return str(e), 500


@app.route("/api/stations")
def get_stations():
    """API: å–å¾—æ¸¬ç«™åˆ—è¡¨ï¼ˆJSONæ ¼å¼ï¼‰"""
    try:
        return json.dumps(target_dict, ensure_ascii=False), 200, {'Content-Type': 'application/json; charset=utf-8'}
    except Exception as e:
        logger.error(f"âŒ Error getting stations: {e}")
        return json.dumps({"error": str(e)}), 500, {'Content-Type': 'application/json; charset=utf-8'}


@app.route("/trace")
def trace_page():
    """æ³¢å½¢é é¢"""
    return render_template("trace.html")


@app.route("/event")
def event_page():
    """äº‹ä»¶é é¢"""
    return render_template("event.html")


@app.route("/dataset")
def dataset_page():
    """è³‡æ–™é›†é é¢"""
    return render_template("dataset.html")


@app.route("/intensityMap")
def map_page():
    """éœ‡åº¦åœ°åœ–é é¢"""
    return render_template("intensityMap.html")


@socketio.on("connect")
def handle_connect():
    """å®¢æˆ¶ç«¯é€£ç·š"""
    logger.info("ğŸ”Œ Client connected")
    socketio.emit("connect_init")


# ========== Mock Data Generators ==========

def generate_mock_wave():
    """ç”Ÿæˆæ¨¡æ“¬æ³¢å½¢è³‡æ–™ - æ¨¡æ“¬çœŸå¯¦ç¶²è·¯å¡è»Šæƒ…æ³
    æŸäº›æ¸¬ç«™å¯èƒ½ç´¯ç©å¥½å¹¾ç§’å¾Œæ‰ä¸€æ¬¡é€é”ï¼Œå®Œå…¨ä¸å¯é æ¸¬çš„æ›´æ–°æ¨¡å¼"""
    logger.info("ğŸŒŠ Starting wave generator with realistic network simulation...")
    logger.info(f"ğŸ“Š Using {len(target_dict)} target stations from eew_target.csv")

    # å¾ target_dict æå–æ¸¬ç«™ä»£ç¢¼
    stations = [station["station"] for station in target_dict]
    logger.info(f"ğŸ“ Loaded stations: {', '.join(stations[:5])}... (total {len(stations)})")

    packet_count = 0

    # ç‚ºæ¯å€‹æ¸¬ç«™ç¶­è­·ç¨ç«‹çš„è³‡æ–™ä½‡åˆ—å’Œç¶²è·¯ç‹€æ…‹
    station_queues = {station: [] for station in stations}
    station_network_state = {
        station: {
            "congestion_level": random.uniform(0, 0.3),  # 0=æš¢é€š, 1=åš´é‡å¡è»Šï¼ˆå¤§éƒ¨åˆ†æ¸¬ç«™ç¶²è·¯è‰¯å¥½ï¼‰
            "burst_probability": random.uniform(0.6, 0.9),  # çˆ†ç™¼å‚³è¼¸æ©Ÿç‡ï¼ˆæé«˜å‚³è¼¸æ©Ÿç‡ï¼‰
            "accumulated_packets": 0,  # ç´¯ç©çš„å°åŒ…æ•¸
            "last_send_time": time.time()
        }
        for station in stations
    }

    def generate_waveform_packet():
        """ç”Ÿæˆå–®ç§’æ³¢å½¢å°åŒ…"""
        t = np.linspace(0, 1, 100)
        p_arrival = random.uniform(0.1, 0.3)
        s_arrival = random.uniform(0.4, 0.7)

        wave_data = (
            np.where(t >= p_arrival,
                     np.exp(-(t - p_arrival) / 0.2) * np.sin(2 * np.pi * 5 * (t - p_arrival)) * random.uniform(0.5, 2),
                     0) +
            np.where(t >= s_arrival,
                     np.exp(-(t - s_arrival) / 0.3) * np.sin(2 * np.pi * 2 * (t - s_arrival)) * random.uniform(2, 8),
                     0) +
            np.random.randn(100) * 0.3
        )

        pga = np.max(np.abs(wave_data))
        return {
            "waveform": wave_data.tolist(),
            "pga": float(pga),
            "status": "active"
        }

    # éåŒæ­¥ç™¼é€åŸ·è¡Œç·’ï¼ˆæ¨¡æ“¬æ¸¬ç«™ç¨ç«‹å‚³è¼¸ï¼‰
    def station_sender_loop():
        """æ¯å€‹æ¸¬ç«™ç¨ç«‹æ±ºå®šä½•æ™‚ç™¼é€ç´¯ç©çš„è³‡æ–™"""
        while True:
            try:
                current_time = time.time()

                # éš¨æ©Ÿé¸æ“‡ä¸€äº›æ¸¬ç«™æª¢æŸ¥æ˜¯å¦è¦ç™¼é€ï¼ˆå¢åŠ æª¢æŸ¥æ•¸é‡ä»¥æé«˜éŸ¿æ‡‰é€Ÿåº¦ï¼‰
                check_stations = random.sample(stations, min(random.randint(20, 40), len(stations)))

                for station in check_stations:
                    state = station_network_state[station]
                    queue = station_queues[station]

                    # æ±ºå®šæ˜¯å¦ç™¼é€ï¼ˆè€ƒæ…®å¡è»Šç¨‹åº¦ã€ç´¯ç©å°åŒ…æ•¸ã€æ™‚é–“é–“éš”ï¼‰
                    time_since_last = current_time - state["last_send_time"]

                    should_send = False

                    if state["accumulated_packets"] > 0:
                        # æƒ…æ³ 1: çˆ†ç™¼å‚³è¼¸ï¼ˆç´¯ç©å¤ªå¤šå°åŒ…å¾Œä¸€æ¬¡é€å‡ºï¼‰
                        if state["accumulated_packets"] >= random.randint(1, 3):  # é™ä½é–¾å€¼ï¼šç´¯ç© 1-3 å€‹å°±å¯èƒ½é€å‡º
                            should_send = random.random() < 0.85  # 85% æ©Ÿç‡é€å‡ºï¼ˆæé«˜å‚³è¼¸ç‡ï¼‰

                        # æƒ…æ³ 2: éš¨æ©Ÿå‚³è¼¸ï¼ˆç¶²è·¯ç‹€æ³å¥½è½‰ï¼‰
                        elif random.random() < state["burst_probability"]:
                            should_send = True

                        # æƒ…æ³ 3: è¶…æ™‚å¼·åˆ¶å‚³è¼¸ï¼ˆé¿å…ç´¯ç©å¤ªä¹…ï¼‰
                        elif time_since_last > 3:  # ç¸®çŸ­è¶…æ™‚æ™‚é–“ï¼š3 ç§’å°±å¼·åˆ¶é€å‡º
                            should_send = True
                            logger.debug(f"â° {station} å¼·åˆ¶å‚³è¼¸ ({state['accumulated_packets']} å€‹ç´¯ç©å°åŒ…)")

                    if should_send and queue:
                        # ä¸€æ¬¡é€å‡ºç´¯ç©çš„æ‰€æœ‰å°åŒ…ï¼ˆå»¶é²è£œå„Ÿï¼‰
                        burst_size = len(queue)

                        # ä¾åºç™¼é€æ¯å€‹ç´¯ç©çš„å°åŒ…ï¼ˆå¾èˆŠåˆ°æ–°ï¼‰
                        # ä½¿ç”¨å°åŒ…è‡ªå·±è¨˜éŒ„çš„ç”Ÿæˆæ™‚é–“æˆ³
                        for packet_with_timestamp in queue:
                            packet_data = packet_with_timestamp["data"]
                            packet_timestamp = packet_with_timestamp["timestamp"]

                            # ä½¿ç”¨ SEED æ ¼å¼ï¼šSM.{station}.01.HLZ
                            seed_station = f"SM.{station}.01.HLZ"
                            wave_packet = {
                                "waveid": f"{seed_station}_{packet_timestamp}",
                                "timestamp": packet_timestamp,
                                "data": {seed_station: packet_data}
                            }

                            socketio.emit("wave_packet", wave_packet)

                        # æ¸…ç©ºä½‡åˆ—
                        station_queues[station] = []
                        state["accumulated_packets"] = 0
                        state["last_send_time"] = current_time

                        if burst_size > 1:
                            # è¨ˆç®—å¯¦éš›å»¶é²æ™‚é–“
                            first_packet_time = queue[0]["timestamp"] / 1000
                            delay_seconds = current_time - first_packet_time
                            logger.debug(f"ğŸ’¥ {station} burst send: {burst_size} packets (delay: {delay_seconds:.1f}s, filling gap)")

                # éš¨æ©ŸçŸ­æš«ä¼‘æ¯ï¼ˆ100-300msï¼‰æ¨¡æ“¬éåŒæ­¥å‚³è¼¸
                time.sleep(random.uniform(0.1, 0.3))

            except Exception as e:
                logger.error(f"âŒ Station sender error: {e}")
                time.sleep(0.5)

    # å•Ÿå‹•éåŒæ­¥ç™¼é€åŸ·è¡Œç·’
    threading.Thread(target=station_sender_loop, daemon=True).start()
    logger.info("ğŸš€ Started asynchronous station sender thread")

    # ä¸»è¿´åœˆï¼šæ¯ç§’ç‚ºæ‰€æœ‰æ¸¬ç«™ç”Ÿæˆè³‡æ–™ä¸¦åŠ å…¥ä½‡åˆ—
    while True:
        try:
            packet_count += 1
            generation_time = time.time()  # è¨˜éŒ„é€™ä¸€è¼ªçš„ç”Ÿæˆæ™‚é–“

            # ç‚ºæ¯å€‹æ¸¬ç«™ç”Ÿæˆæ–°çš„æ³¢å½¢è³‡æ–™ä¸¦åŠ å…¥ä½‡åˆ—
            for station in stations:
                packet = generate_waveform_packet()
                # å°‡å°åŒ…èˆ‡ç”Ÿæˆæ™‚é–“ä¸€èµ·å­˜å…¥ä½‡åˆ—
                station_queues[station].append({
                    "data": packet,
                    "timestamp": int(generation_time * 1000)  # è¨˜éŒ„ç”Ÿæˆæ™‚çš„æ™‚é–“æˆ³
                })
                station_network_state[station]["accumulated_packets"] += 1

            # æ¯ 10 ç§’è¨˜éŒ„ä¸€æ¬¡ç‹€æ…‹
            if packet_count % 10 == 0:
                congested_stations = [s for s in stations if station_network_state[s]["accumulated_packets"] > 3]
                avg_queue = np.mean([station_network_state[s]["accumulated_packets"] for s in stations])
                logger.info(f"ğŸ“ˆ Generated {packet_count} waves | Avg queue: {avg_queue:.1f} | Congested: {len(congested_stations)}/{len(stations)}")

            # æ¯ 20 ç§’éš¨æ©Ÿèª¿æ•´ç¶²è·¯ç‹€æ³ï¼ˆåªå½±éŸ¿å°‘æ•¸æ¸¬ç«™ï¼‰
            if packet_count % 20 == 0:
                # éš¨æ©Ÿé¸æ“‡ 2-5 å€‹æ¸¬ç«™ï¼ˆè€Œé 5-15 å€‹ï¼‰
                affected_stations = random.sample(stations, min(random.randint(2, 5), len(stations)))
                for station in affected_stations:
                    state = station_network_state[station]
                    # å¤§éƒ¨åˆ†æ™‚å€™ä¿æŒè‰¯å¥½ç¶²è·¯ï¼ˆ0-0.4ï¼‰ï¼Œå¶çˆ¾å¡è»Šï¼ˆ0.4-0.8ï¼‰
                    state["congestion_level"] = random.uniform(0, 0.6)
                    state["burst_probability"] = random.uniform(0.5, 0.9)  # ä¿æŒè¼ƒé«˜çš„å‚³è¼¸æ©Ÿç‡
                logger.debug(f"ğŸ”„ Updated network conditions for {len(affected_stations)} stations")

            # æ¨¡æ“¬æ¯ç§’ç”Ÿæˆè³‡æ–™
            time.sleep(1.0)

        except Exception as e:
            logger.error(f"âŒ Wave generator error: {e}")
            time.sleep(1)


def generate_mock_event():
    """ç”Ÿæˆæ¨¡æ“¬åœ°éœ‡äº‹ä»¶"""
    logger.info("ğŸ“ Starting event generator...")
    time.sleep(5)  # ç­‰å¾… 5 ç§’å¾Œé–‹å§‹

    event_count = 0

    while True:
        try:
            event_count += 1
            num_stations = random.randint(3, 8)  # 3-8 å€‹æ¸¬ç«™è§¸ç™¼
            stations = random.sample(["HL1A", "NACB", "CHY1", "TAP1", "NCU1", "TPUB", "KAU1"], num_stations)

            event_data = {}

            for station in stations:
                # ç”Ÿæˆä¸‰è»¸æ³¢å½¢ï¼ˆ3000 é» = 30 ç§’ @ 100Hzï¼‰
                t = np.linspace(0, 30, 3000)

                # P æ³¢åˆ°é”ï¼ˆæ¨¡æ“¬åœ°éœ‡æ³¢å½¢ï¼‰
                p_arrival = random.uniform(2, 5)
                s_arrival = p_arrival + random.uniform(3, 8)

                def seismic_wave(t, arrival_time, amplitude):
                    """æ¨¡æ“¬åœ°éœ‡æ³¢"""
                    wave = np.zeros_like(t)
                    mask = t >= arrival_time
                    wave[mask] = amplitude * np.exp(-(t[mask] - arrival_time) / 5) * np.sin(2 * np.pi * 3 * (t[mask] - arrival_time))
                    return wave

                pga = random.uniform(0.5, 8.0)  # 0.5~8.0 gal

                z_wave = (
                    seismic_wave(t, p_arrival, pga * 0.7) +
                    seismic_wave(t, s_arrival, pga * 1.5) +
                    np.random.randn(3000) * 0.3
                )

                n_wave = (
                    seismic_wave(t, s_arrival, pga * 1.2) +
                    np.random.randn(3000) * 0.3
                )

                e_wave = (
                    seismic_wave(t, s_arrival, pga * 1.0) +
                    np.random.randn(3000) * 0.3
                )

                event_data[f"SM.{station}.01.HLZ"] = {
                    "pick": {
                        "station": station,
                        "pick_time": str(time.time()),
                        "pga": f"{pga:.2f}",
                        "intensity": str(random.randint(1, 5))
                    },
                    "trace": {
                        "Z": z_wave.tolist(),
                        "N": n_wave.tolist(),
                        "E": e_wave.tolist(),
                    }
                }

            logger.info(f"ğŸ“¡ Emitting event #{event_count} with {len(event_data)} stations")
            socketio.emit("event_data", event_data)

            # éš¨æ©Ÿé–“éš” 10-30 ç§’
            time.sleep(random.uniform(10, 15))

        except Exception as e:
            logger.error(f"âŒ Event generator error: {e}")
            time.sleep(5)


def generate_mock_dataset():
    """ç”Ÿæˆæ¨¡æ“¬é æ¸¬è³‡æ–™é›†"""
    logger.info("ğŸ“Š Starting dataset generator...")
    time.sleep(8)  # ç­‰å¾… 8 ç§’å¾Œé–‹å§‹

    dataset_count = 0

    while True:
        try:
            dataset_count += 1

            # éš¨æ©Ÿé¸æ“‡è§¸ç™¼æ¸¬ç«™
            source_stations = random.sample(["HL1A", "NACB", "CHY1"], random.randint(1, 3))

            # é æ¸¬ç›®æ¨™æ¸¬ç«™ï¼ˆå¾ target_dict é¸å–ï¼‰
            num_targets = min(len(target_dict), random.randint(10, 30))
            target_stations = random.sample(target_dict, num_targets)

            # ç”Ÿæˆé æ¸¬è³‡æ–™
            target_names = [t["station"] for t in target_stations]
            pga_values = [random.uniform(0.1, 10.0) for _ in range(num_targets)]

            # éœ‡åº¦è¨ˆç®—ï¼ˆç°¡åŒ–ç‰ˆï¼‰
            def pga_to_intensity(pga):
                if pga < 0.8:
                    return 0
                elif pga < 2.5:
                    return 1
                elif pga < 8.0:
                    return 2
                elif pga < 25:
                    return 3
                elif pga < 80:
                    return 4
                elif pga < 250:
                    return 5
                elif pga < 400:
                    return 6
                else:
                    return 7

            intensity_values = [pga_to_intensity(pga) for pga in pga_values]

            dataset = {
                "station_name": source_stations,
                "target_name": target_names,
                "pga": pga_values,
                "intensity": intensity_values
            }

            logger.info(f"ğŸ“ˆ Emitting dataset #{dataset_count} with {num_targets} targets")
            socketio.emit("dataset_data", dataset)

            # éš¨æ©Ÿé–“éš” 15-30 ç§’
            time.sleep(random.uniform(15, 30))

        except Exception as e:
            logger.error(f"âŒ Dataset generator error: {e}")
            time.sleep(5)


# ========== Main Entry Point ==========

def start_mock_server():
    """å•Ÿå‹• Mock Server"""
    logger.info("=" * 60)
    logger.info("ğŸš€ TTSAM Mock Server Starting...")
    logger.info("=" * 60)
    logger.info("ğŸ“ Server will run at: http://0.0.0.0:5001")
    logger.info("ğŸŒ Available pages:")
    logger.info("   - http://localhost:5001/          (é¦–é )")
    logger.info("   - http://localhost:5001/trace     (æ³¢å½¢)")
    logger.info("   - http://localhost:5001/event     (äº‹ä»¶)")
    logger.info("   - http://localhost:5001/dataset   (è³‡æ–™é›†)")
    logger.info("   - http://localhost:5001/intensityMap (éœ‡åº¦åœ°åœ–)")
    logger.info("=" * 60)
    logger.info("ğŸ“Š Mock data generators will start in background...")
    logger.info("   - Wave packets: Realistic network congestion simulation ğŸŒ")
    logger.info("     * Each station generates 1 packet/second (100 samples @ 100Hz)")
    logger.info("     * Packets accumulate in queue during congestion")
    logger.info("     * Burst transmission: 2-5 packets sent together with correct timestamps")
    logger.info("     * Delay compensation: backfills missing time periods when burst arrives")
    logger.info("     * Asynchronous delivery: stations send independently")
    logger.info("     * NO predictable update cycle - fully dynamic!")
    logger.info("   - Events: every 10-30s")
    logger.info("   - Datasets: every 15-30s")
    logger.info("=" * 60)

    # å•Ÿå‹•æ¨¡æ“¬è³‡æ–™ç”Ÿæˆå™¨ï¼ˆèƒŒæ™¯åŸ·è¡Œç·’ï¼‰
    threading.Thread(target=generate_mock_wave, daemon=True).start()
    threading.Thread(target=generate_mock_event, daemon=True).start()
    threading.Thread(target=generate_mock_dataset, daemon=True).start()

    # å•Ÿå‹• Flask + SocketIO server
    socketio.run(
        app,
        host="0.0.0.0",
        port=5001,
        debug=False,  # é¿å…é‡è¤‡å•Ÿå‹•
        use_reloader=False
    )


if __name__ == "__main__":
    start_mock_server()

